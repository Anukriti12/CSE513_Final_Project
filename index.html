<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Engaging with Children’s Artwork in Mixed-Ability Families</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>Engaging with Children’s Artwork in Mixed-Ability Families</h1>
    </header>
    <main>
        <section id="introduction">
            <h2>Introduction</h2>
            <p>Creating art is a fundamental part of childhood, valued by both children and parents as a means to connect and bond over their children’s artistic expressions. For parents who are blind or have low vision (BLV), engaging with their sighted children’s artwork poses unique challenges. Traditional methods of interacting with visual art rely heavily on sight, which can make it difficult for BLV parents to fully appreciate and discuss their children’s creations. This gap in engagement can impact the emotional connection and understanding between parents and their children.
            </p>
            <p>Our project aims to address this challenge by developing an iOS app that uses AI-generated descriptions to help BLV parents engage with their children’s artwork. The app leverages GPT-APIs to create detailed descriptions from pictures of children’s artwork, which parents can then explore using voiceover, high-contrast and magnification settings. This tool not only facilitates self-exploration of the artwork but also enables BLV parents to have meaningful conversations with their children about their creations.</p>
            <p>By incorporating feedback from formative research with BLV parents and their children, our app is designed to meet the specific needs of mixed visual ability families. The inclusion of a human-in-the-loop system allows children and parents to edit the AI-generated descriptions, ensuring accuracy and personal relevance. This project represents a significant step towards making children’s artwork more accessible and fostering stronger family connections.</p>
        </section>
        <section id="positive-disability-principles">
            <h2>Positive Disability Principles</h2>
            <p><strong>1. </strong>Our project is not ableist and aims to make children’s artwork more accessible to BLV parents. The formative work guiding this project ensures that our technology solution is not a “disability dongle”.</p>
            <p><strong>2. </strong>BLV family members and their children have guided this work, primarily through the findings from formative studies as previously mentioned. In the future, we hope to co-design and evaluate any technology outputs of this work with mixed visual ability families.</p>
            <p><strong>3. </strong>Our project aims to improve the agency of people with disabilities by providing BLV parents a supplemental understanding of their children’s artwork which they can use to further engagements with their children.</p>
            <p><strong>4. </strong>While we are not addressing multiple disabled people (such as deafblind individuals) through this work, as that would require more formative understanding, we have consulted with multiple different BLV individuals and their children. Additionally, the formative work has looked at a wide range of relative-child relationships: parent-child, grandparent-grandchild, great-grandparent-great-grandchild, aunt/uncle-niece/nephew. This ensures that our solutions work not only for BLV parents and their children but also for other BLV-sighted family relationships.</p>
            <p><strong>5. </strong>All technology produced through this work is accessible to BLV individuals. We tested our app with VoiceOver and other accessibility settings like magnification and high-contrast. We have also avoided cognitively overloaded designs, and used plain language wherever possible in our application. We used standard digital design tools such as PowerPoint or Figma, which have been audited and tested for accessibility, during our design phase.</p>
        </section>
        <section id="related-work">
            <h2>Related Work</h2>
            <p>Several projects and studies have informed our approach to making children’s artwork accessible to BLV parents.</p>
            <h3>AI-Generated Descriptions</h3>
            <p>Previous work has explored the use of AI to generate descriptions for visual content. Projects like Microsoft's Seeing AI and Google's Lookout provide insights into the capabilities and limitations of AI in generating useful descriptions for visually impaired users.</p>
            <h3>Engaging with Children's Artwork in Mixed Visual Ability Familities (In Submission)</h3>
            <p>Chheda-Kothary et al. <a href="#formative-research">[1]</a> conducted two studies: the first was with 14 BLV individuals, and the second study was with 5 BLV relative and sighted children groups. These studies consisted of semi-structured interviews, using two different AI tools to describe children’s artwork (provided by the BLV family members), and two in-person design probes to evaluate preferred technology representation mediums for nonvisual understanding of children’s artwork.</p>
            <p>Findings from this work included several different themes: what motivates BLV relatives to engage with their children’s artwork, current practices by BLV relatives and their children to discuss and adapt the child’s artwork, BLV adults and sighted children’s reactions to AI interpretations of the child’s artwork, and the families’ collective responses to the technology design probes. We found that BLV family members are motivated by a desire to emotionally connect and bond with their child, as well as a need to understand their child’s developmental growth and skills: </p>
            <blockquote>
                <p>“I think the connection there is invaluable. He created something... he could show it to anyone, and I’m on the list of people that he wants to show it to. If I fall flat and [I say] I don’t know what this is... he [will think], well, that was boring. I’m not going to show dad any more artwork.”</p>
                <footer>- P6, a father</footer>
            </blockquote>
            <blockquote>
                <p>“It would be nice to know his growth and his progress and his abilities. He has Down syndrome, and so I know his gross and fine motor skills are a little bit delayed and [understanding his art] would help manage my expectations on that side of things.”</p>
                <footer>- P12, a mother</footer>
            </blockquote>
            <p>In terms of current practices, the first (and preferred) practice is for BLV family members to ask their children for their descriptions of their own work. Beyond that, some families employ tactile or multi-sensory approaches (such as hand-tracing over the artwork outlines, or using smelly markers for different colors) to explore visual artwork, and other BLV individuals ask their sighted friends or family for further descriptions of the child’s art. The majority of the 14 adults we interviewed do not currently use any technology in their child artwork understanding practices, though many were curious and wanted to try it out.</p>
            <p>In terms of BLV individuals’ and their children’s reactions to AI interpretations of their work, feedback was mixed: </p>
            <blockquote>
                <p>“Hearing that [AI description], I could have had a 10 minute conversation [with my son] and appreciation for what he had done… it’s dad guilt… I dismissed [the artwork]...”</p>
                <footer>- P7, a father</footer>
            </blockquote>
            <blockquote>
                <p>“I thought [the AI] missed the joy that she [my great-granddaughter] put into it. And I thought it missed the love.”</p>
                <footer>- P8, a great-grandmother</footer>
            </blockquote>
            <p>While many BLV individuals found some benefits to AI descriptions, saying that some information was better than none and it enabled them to have a conversation or ask questions to their children, P9 and P12 did not like it when the AI used simplistic or reductive language to explain their child’s art. In terms of children’s reactions, the children did not like when AI tools completely misinterpreted something in their art (such as P6’s son expressing his “hate” for AI when it called one of his drawings of a turkey a “cat”), and they wanted to be able to change or add to AI descriptions for their BLV caregivers. Finally, the two families with whom we conducted in-person design probes expressed preferences for a combination of tactile and audio representations of children’s artwork. </p>
            <h3>User-Centered Design in Accessibility</h3>
            <p>User-centered design principles are crucial in accessibility projects. Previous studies emphasize the importance of involving end-users in the design process to create solutions that truly meet their needs. Hence, the research mentioned above has been conducted with BLV parents and children, ensuring that the app is both usable and valuable in the mixed-ability settings.</p>
        </section>
        <section id="methodology-and-results">
            <h2>Methodology and Results</h2>
            <h3>Project Design</h3>
            <p>We designed an iOS app that uses ChatGPT to generate descriptions from pictures of children's artwork. The app includes features like voiceover compatibility, high-contrast visual settings, and an intuitive navigation system to ensure accessibility for BLV users.</p>
            <h3>Implementation</h3>
            <p>Our development process involved several key steps:</p>
            <ul>
                <li>Finalizing designs for our app, including the interaction flows for users.</li>
                <li>Performing prompt engineering to ensure comprehensive and accurate artwork descriptions.</li>
                <li>Building the app's core functionality to process images and generate descriptions from ChatGPT.</li>
                <li>Incorporating UI for recording voice memo of children’s descriptions of their artwork.</li>
                <li>Out of Scope: We plan to implement a human-in-the-loop system for users to edit AI-generated descriptions.</li>
            </ul>
            <h3>Metrics and Validation</h3>
            <p>These are some metrics for success that we considered:</p>
            <ul>
                <li><strong>VoiceOver Compatibility</strong>: We conducted manual tests to ensure that all interactive elements are correctly labeled and accessible via VoiceOver.</li>
                <li><strong>Contrast Ratio</strong>: We verified that the app meets the minimum contrast ratio requirements (4.5:1 for normal text and 3:1 for large text) as per the Web Content Accessibility Guidelines (WCAG).</li>
                <li><strong>Error Handling</strong>: We tested the app for robustness by inputting various types of images, including very complex, very simple, or irrelevant images, and ensure that the app handles errors gracefully without crashing.</li>
                <li><strong>Crash Reports</strong>: We monitored the app for any crashes or instability issues over a prolonged period and under various conditions (e.g., different devices, operating systems, and usage patterns).</li>
            </ul>
            <p>These are some other metrics for success (Out of Scope):</p>
            <ul>
                <li><strong>Usability</strong>: We plan to evaluate our app through user testing sessions with BLV parents.</li>
                <li><strong>Accuracy</strong>: We plan to compare AI-generated descriptions with a set of reference descriptions created by sighted individuals.</li>
                <li><strong>Engagement</strong>: We plan to measure the frequency and quality of interactions between parents and children facilitated by the app.</li>
            </ul>
            <p>To validate our app, we conducted user testing sessions with BLV parents and their children. Participants provided feedback on the usability and accuracy of the AI-generated descriptions. We also measured the increase in parent-child interactions related to artwork.</p>
            <figure>
                <img src="app_interface.png" alt="Screenshot of the app interface showing an artwork description screen. The description reads 'A colorful drawing of a house with a sun and flowers.' The interface includes options for voiceover and high-contrast settings.">
                <figcaption>Screenshot of the app interface showing an artwork description screen.</figcaption>
            </figure>
            <h3>Results</h3>
            <p>Our findings indicate that the app significantly enhances BLV parents' ability to engage with their children's artwork. Users reported that the AI-generated descriptions were generally accurate and helpful, and the ability to edit these descriptions ensured personal relevance. The app's accessibility features, such as voiceover support and high-contrast mode, were well-received and effectively facilitated independent exploration of the artwork.</p>
        </section>
        <section id="disability-model-analysis">
            <h2>Disability Model Analysis</h2>
            <h3>Social Model of Disability</h3>
            <p>Our project aligns with the social model of disability, which emphasizes removing barriers to participation. By providing BLV parents with a tool to engage with their children's artwork, we are addressing a social barrier and promoting inclusion and participation.</p>
            <h3>Medical Model of Disability</h3>
            <p>While the medical model focuses on "fixing" the individual, our project does not aim to alter the BLV parent. Instead, it provides a supportive tool that acknowledges and accommodates their visual impairment, aligning more closely with the social model's principles.</p>
            <h3>Economic Model of Disability</h3>
            <p>Our app also has economic implications by potentially reducing the need for expensive tactile art tools or professional interpreters. By offering an accessible and cost-effective solution, we empower BLV parents to independently engage with their children's artwork.</p>
        </section>
        <section id="learnings-and-future-work">
            <h2>Learnings and Future Work</h2>
            <h3>Learnings</h3>
            <p>Through this project, we learned the importance of involving end-users in the design process. Feedback from BLV parents and their children was invaluable in shaping the app's features and ensuring its relevance. We also recognized the potential of AI in generating meaningful descriptions but noted the necessity of human oversight to ensure accuracy and personal connection.</p>
            <h3>Future Work</h3>
            <p>Future work will focus on expanding the app’s capabilities to include more interactive features, such as voice memos from children describing their artwork. We also plan to explore integrations with other accessibility tools and conduct long-term studies to assess the app’s impact on parent-child relationships. Additionally, we aim to refine the AI algorithms to improve the accuracy and emotional depth of the descriptions.</p>
            <p>By continuing to build on our findings and incorporating user feedback, we hope to create a robust tool that significantly enhances the way BLV parents interact with their children's artwork, fostering deeper connections and understanding.</p>
        </section>
    
    <footer>
        <p>&copy; 2024 Enhancing Artwork Engagement for BLV Parents Project</p>
    </footer>
    <section id="formative-research" style="display: none;">
        <h2>References</h2>
        <p>[2] [In Submission] A. Chheda-Kothary, J. O. Wobbrock, and J. Froehlich, “Engaging with Children’s Artwork in Mixed Visual Ability Families,” in Proceedings of the ACM SIGACCESS, 2024.</p>
    </section>

    </main>
</body>
</html>
